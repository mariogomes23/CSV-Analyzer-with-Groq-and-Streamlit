# Chatbot com Llama e Streamlit

Este é um projeto de chatbot desenvolvido com o modelo **Llama** e a biblioteca **Streamlit** para fornecer uma interface interativa de conversa. Siga as instruções abaixo para configurar e executar o projeto localmente.

## Requisitos

- **Python 3.7+** 
- **Pip** (gerenciador de pacotes do Python)
- **Modelo Llama** instalado e configurado em sua máquina

### Dependências

As dependências do projeto estão listadas no arquivo `requisitos.txt`. Este arquivo inclui bibliotecas como Streamlit e outras que o Llama pode exigir.

## Passo a Passo para Rodar o Projeto

### 1. Clone o Repositório

Clone o repositório para sua máquina local e navegue até o diretório do projeto:

```bash
git clonehttps://github.com/mariogomes23/chat-bot-ollama
cd chat-bot-ollama
